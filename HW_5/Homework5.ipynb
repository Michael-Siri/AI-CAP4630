{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework5",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOppL0Y3yFej26QrhSHCmpc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michael-Siri/AI-CAP4630/blob/master/HW_5/Homework5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYW_JHdVbkKT",
        "colab_type": "text"
      },
      "source": [
        "# Homework 5\n",
        "Summarize and describe the different concepts/methods/algorithms that you have learned in this course.\n",
        "\n",
        "*For this assignment this we are summarizing for comprehension, I attempted to use as little code-snippets as possible to avoid jargon.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9G1GB5YbsvL",
        "colab_type": "text"
      },
      "source": [
        "#1. General Concepts\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBE8p9jpgJ5Z",
        "colab_type": "text"
      },
      "source": [
        "Artificial intelligence, machine learning and deep learning are terms often used to describe intelligent software and is commonly used interchangeably. However, machine learning is a subset of artificial intelligence and deep learning is a subset of machine learning.\n",
        "\n",
        "$AI > ML > DL$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfxPmfgOfYV-",
        "colab_type": "text"
      },
      "source": [
        "## Artificial Intelligence (AI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw8Vf0cCgZIm",
        "colab_type": "text"
      },
      "source": [
        "A common description of Artificial Intelligence is the capability of a machine to imitate intelligent human behavior. Imitating human behavior is a very broad term and so is AI. The range of AI can begin from a pile of simple if-then statements, to a more complex algorithm.\n",
        "If the pile of if-then statements are gathered into a collection, it forms Symbolic Artificial Intelligence.\n",
        "\n",
        "Symbolic AI operates in the form of:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJW3b3RcU7Sx",
        "colab_type": "text"
      },
      "source": [
        "$AI =\n",
        " \\begin{matrix}\n",
        "  Input & \\cdots > & + & \\cdots & + \\\\\n",
        "    & & \\vdots &  & \\vdots & \\cdots > & Output \\\\\n",
        "  Rules & \\cdots > & + & \\cdots & +\n",
        " \\end{matrix}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il9YdSw0fYsB",
        "colab_type": "text"
      },
      "source": [
        "## Machine Learning (ML)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeCYrR1hgZ4T",
        "colab_type": "text"
      },
      "source": [
        "The subset of Artificial Intelligence, Machine Learning, focuses on the system that is able to modify itself without human intervention; Machine Learning is dynamic and creates rules from the input and output unlike Symbolic AI.\n",
        "ML, when exposed to new data, will attempt to minimize error and increase the accuracy of predictions as an optimization algorithm.\n",
        "\n",
        "\n",
        "Machine Learning operates in the form of:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItxXBsMmVBMl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        " $ML =\n",
        "  \\begin{matrix}\n",
        "  Input & \\cdots > & + & \\cdots & + \\\\\n",
        "    & & \\vdots &  & \\vdots & \\cdots > & Rules \\\\\n",
        "  Output & \\cdots > & + & \\cdots & +\n",
        " \\end{matrix} $\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W866jRddfZAi",
        "colab_type": "text"
      },
      "source": [
        "##Deep Learning (DL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_gKPnqZfZdU",
        "colab_type": "text"
      },
      "source": [
        "As a subset of Machine learning, Deep Learning utilizes neural networks, or set of algorithms designed to recognize certain patterns. DL attemps to map its inputs to outputs and finds a correlation in the process of learning; Deep also refers to the number of layers in a neural network.\n",
        "\n",
        "\n",
        "*   \"a field of study that gives computers the ability to learn without being explicitly programmed\" - Arthur Samuel\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkkmpMkd3jb9",
        "colab_type": "text"
      },
      "source": [
        "#2. Basic Concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn6d8auc3qJz",
        "colab_type": "text"
      },
      "source": [
        "##Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC42nbSEGUwa",
        "colab_type": "text"
      },
      "source": [
        "Linear regression models the relationship between a dependent variable and one or more independent variables; This is considered a common statistical data analysis technique and can be considered simple linear regression or multiple linear regression depending on the number of independent variables.\n",
        "This model assumes the relationship between the variables are linear.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In Machine Learning, the ***simple linear regression*** equation for a model is as follows:\n",
        "\n",
        "\n",
        "\n",
        "$Where:$\n",
        "\n",
        "$y = $ the predicted label\n",
        "\n",
        "$b = $ the bias\n",
        "\n",
        "$w_{1} = $ the weight of feature 1, or slope\n",
        "\n",
        "$x_{1} = $ a feature or known input\n",
        "\n",
        "The Model is $y = b + w_{1}x_{1}$\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "In ***multiple linear regression*** with two or more independent variables, each feature $x_{1},x_{2}... x_{n} $ each contains a separate weight of $w_{1},w_{2}... w_{n} $\n",
        "\n",
        "An example of a model with 3 independent variables will look like this:\n",
        "\n",
        "The model is $y = b + w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3}$ = b + $\\sum_{j=1}^3 w_{j}x_{j}$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XckYrMue3p9P",
        "colab_type": "text"
      },
      "source": [
        "##Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGi5kNsMUHNp",
        "colab_type": "text"
      },
      "source": [
        "Logistic regression is a classification algorithm and very similar to linear regression but the independent variable are not numbers, instead similar to yes/no or 1/0 responses. This is mainly used for prediction of the dependent variable's category; the weighted sum of the inputs pass through a sigmoid function to map the values between 0 and 1.\n",
        "\n",
        "The equation for ***logistic regression*** is:\n",
        "\n",
        "$log\\frac{y}{1-y} = b_{0} + b_{1}x_{1} + b_{2}x_{2} + b_{3}x_{3} + ... + b_{n}x_{n}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTFfgHIF3BAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  res = 1/(1+np.exp(x))\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWY7KOIx3pop",
        "colab_type": "text"
      },
      "source": [
        "##Gradients & Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvWfELBtYM1v",
        "colab_type": "text"
      },
      "source": [
        "A gradient descent is an *optimization* algorithm when training a model. Assuming the loss function of a model to be convex and has only one minimum,\n",
        "calculating the loss function for all parameter values is inefficient for finding it. \n",
        "\n",
        "Gradient descent picks a starting value and calculates the loss function and decides which why is \"warmer\" or \"colder\" depending on the increase of the loss function. The algorithm uses a learning rate to decide how far to take a step to the next point; Eventually it converges upon a minimum.\n",
        "\n",
        "Types of gradient descent mainly are separated by the amount of data used:\n",
        "\n",
        "**Batch Gradient Descent:**\n",
        "The standard original model that calculates the error only after all examples have been evaluated. The batch size is the size of the training set.\n",
        "\n",
        "\n",
        "**Stochastic Gradient Descent (SGD):**\n",
        "\n",
        "SGD updates the parameters after training each example 1 by 1. The batch size is one.\n",
        "\n",
        "\n",
        "**Mini-Batch Gradient Descent:**\n",
        "\n",
        "The training set is split into batches and is the most common type for deep learning. A mixture of batch gradient descent and SGD, mini-match gradient descent updates the parameters after a specified amount of batch size has been evaluated.\n",
        "The batch size is 1 < n < size of training set.\n",
        "\n",
        "\n",
        "The gradient descent algorithm updates the starting point as follows: \n",
        "\n",
        "$w <= w - \\alpha \\nabla\t L $\n",
        "\n",
        "where $\\alpha$ is the learning rate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaIcGA3f3pJT",
        "colab_type": "text"
      },
      "source": [
        "#3. Building a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLvmh0uAOcuv",
        "colab_type": "text"
      },
      "source": [
        "##Convolutional Neural Networks (Convnets)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCW8wT5xRWKS",
        "colab_type": "text"
      },
      "source": [
        "Convolutional neural network is a deep learning algorithm and is also similar to regular neural networks, in that they receive an input, transform it using hidden layers, and the last layer is called the output layer. Convnet input consists of images and their architecture are more focused on performing a better fitting to the image dataset than regular neural networks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dydlVtTTObr7",
        "colab_type": "text"
      },
      "source": [
        "##Structure of Convnets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoODKqCDSf_v",
        "colab_type": "text"
      },
      "source": [
        "###Convolutional Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awOqhX8wUBTR",
        "colab_type": "text"
      },
      "source": [
        "The convolution layers extract high-level features from the input image;  To reduce large matrices into a form that is easier to process while retaining features for good predictions. In the case that the dimensions of the output is reduced because of the kernel, a Same padding or Valid padding can be applied to offset this. \n",
        "\n",
        "Homework 4: Question 1 is a perfect example of convolution. [Here](https://github.com/Michael-Siri/AI-CAP4630/blob/master/HW_4/HW4Question1.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvGHVS7kSmz7",
        "colab_type": "text"
      },
      "source": [
        "###Pooling layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMEmnbtKVuJU",
        "colab_type": "text"
      },
      "source": [
        "The pooling layers attempts to reduce the spatial size from the previous feature; It is similar to the convolution process. The two types of pooling are Max Pooling and Average Pooling that is applied with the kernel. Max Pooling returns the maximum value of the positions covered by the kernel and average pooling returns the average of all the values.\n",
        "\n",
        "\n",
        "Homework 4: Question 2 deals with maxpooling as a good example. [Here](https://github.com/Michael-Siri/AI-CAP4630/blob/master/HW_4/Homework4Question2.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIFELZA7SnI5",
        "colab_type": "text"
      },
      "source": [
        "###Fully-Connected layers\n",
        "\n",
        "The classification layer, where in a series of epochs/ dense layers, the information is classified according to their features.\n",
        "\n",
        "Homework 4: Question 3 deals with Convolutional neural network architecture using VGGNet and changing it to other algorithms such as ResNet or Xception. [Here](https://github.com/Michael-Siri/AI-CAP4630/blob/master/HW_4/Homework4Question3part1.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkVg10XweKR5",
        "colab_type": "text"
      },
      "source": [
        "#4. Comping the Model\n",
        "\n",
        "Once a network architecture is defined, 2 things still need to be accomplished;\n",
        "They are the Loss function and Optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4NZa0DqeMXW",
        "colab_type": "text"
      },
      "source": [
        "##Loss Function (objective function)\n",
        "A loss function generates the error of a single training example, and is typically used for minimizing cost with an optimization method such as gradient descent; It is also used as a measure of success for the current task.\n",
        "\n",
        "The loss functions learned about in this course are:\n",
        "\n",
        "**Squared Error Loss**: The square difference between actual and predicted values\n",
        "\n",
        "$L = (y - f(x))^2$\n",
        "\n",
        "**Binary Cross Entropy Loss:** also named Sigmoid Cross-Entropy loss\n",
        "\n",
        "$L = (Y)(-log(Y_{pred})) + (1-Y)(-log(1-Y_{pred}) $\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK959B3q2ZRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bce(y, a):\n",
        "  res = -y*np.log10(a)-(1-y)*np.log10(1-a)\n",
        "  return res\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHdIkFJfeQSX",
        "colab_type": "text"
      },
      "source": [
        "##Optimizer\n",
        "Optimizers react to the loss function and update the model in response, attempting to efficiently and accurately make a prediction. We've already discussed multiple optimizers in Gradient & Gradient Descent on Section 2 Basic concepts. Nevertheless, there are multiple types of optimizers such as:\n",
        "\n",
        "*   Adagrad\n",
        "*   RMSprop\n",
        "*   Adadelta\n",
        "*   Adam\n",
        "*   Adamax\n",
        "*   Nadam\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0btAX_NhHpx",
        "colab_type": "text"
      },
      "source": [
        "##Learning Rate\n",
        "The learning rate controls how quickly a neural network learns a problem. The step size that a model applies to each step of the problem is the learning rate and is also a hyperparameter for your neural network.\n",
        "\n",
        "A good learning rate is dependent on your training set and is usually covered via trial and error. The range of learning rates can vary between 1.0 to 10^-6.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUKRlNnBhW_b",
        "colab_type": "text"
      },
      "source": [
        "#5. Training a Model\n",
        "There are a few problems that may impact the accuracy of a machine learning model. A model may be overfit, underfit, or balanced; The training and test set split which is taught in this class is to avoid these errors and adjust the models adequately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEOA6TUohZiV",
        "colab_type": "text"
      },
      "source": [
        "## Overfitting\n",
        "\n",
        "Overfitting is when your model performs exceptionally well to your training data but not on the testing data or any new information. This is usually because the model accepts irrevelant information as part of it's algorithm or the \"noise\" of the data. If the data fits the model too well with low bias and high variance, new data will not be categorized completely.\n",
        "\n",
        "The fixes for this may be both removing features or training with *more* data. In the off chance where you capture a specific set of data, more samples may normalize your data. Removing features that are less important will remove more noise from a redundant model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTy5xDgohb37",
        "colab_type": "text"
      },
      "source": [
        "##Underfitting\n",
        "\n",
        "Underfitting occurs when the model performs poorly on the training set; It is unable to create a proper prediction based on the current data and there may be a few causes for this.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   The wrong type of data, linear model with nonlinear data\n",
        "*   Not enough data to create an accurate model\n",
        "*   The model is too simplistic and doesn't have enough features\n",
        "\n",
        "Adjusting the model by adding more features is a solution to an underfitted training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKYNRL2qhdyW",
        "colab_type": "text"
      },
      "source": [
        "#6. Finetuning a pretrained model\n",
        "Finetuning is the action of taking a pretrained model such as VGG16 and modify it to have it work on a new set of a data.\n",
        "In practice, it's more likely that we finetune an existing model than training a covnet on a small dataset to avoid overfitting or underfitting; If the dataset we plan to use is not too different from the dataset in the pre-trained models, then finetuning is the recommended choice. \n",
        "\n",
        "There are multiple ways to finetune a model and here are some general guidelines to approach an implementation.\n",
        "\n",
        "Truncating the last layer of the pretrained network, using a smaller learning rate, or freezing the weights of the first few layers of the pre-trained network are all common approaches.\n",
        "\n",
        "However, we will be discussing our approach in Homework 4 Assignment 3 located [Here.](https://github.com/Michael-Siri/AI-CAP4630/blob/master/HW_4/Homework4Question3part2.ipynb)\n",
        "\n",
        "Importing the data from an existing deep learning network, we use Xception.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoU8wAGDR3jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import Xception\n",
        "\n",
        "conv_base = Xception(\n",
        "    weights='imagenet', \n",
        "    include_top=False, \n",
        "    input_shape=(150, 150, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYEPTy5xSIAH",
        "colab_type": "text"
      },
      "source": [
        "Afterwards we added more layers to the model, removing is also optional. \n",
        "\n",
        "Then freezing layers that no longer need to be modified when training the new models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8xsuWbATeX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qMGWNVdTvKI",
        "colab_type": "text"
      },
      "source": [
        "Finetuning the model can also be done by unfreezing certain layers in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8FnepxoUCtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'conv2d_4':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-la7ivvTWNyN",
        "colab_type": "text"
      },
      "source": [
        "Afterwards the data can be trained on the new model for another task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTwVLeWwUDSj",
        "colab_type": "text"
      },
      "source": [
        "In this homework, the layer unfrozen is 'conv2d_4' which is free to have their weights modified.\n",
        "\n",
        " All the weights of the other layers will stay the same and the result of the new model will be displayed at the end.\n",
        "\n",
        "This exercise can save a lot of time and resources by using pre-trained models, certain cases where new data is limited and training data from scratch is not possible, fine-tuning can be incorporated fairly easily with some slight modifications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ7QYjvIXGvH",
        "colab_type": "text"
      },
      "source": [
        "The layers of your model can be found here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lsj3xOXPWcmV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b299c75c-d91b-4a3d-da3d-dc852e8ed808"
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 36, 36, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 36, 36, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 36, 36, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 18, 18, 256)  32768       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 18, 18, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 18, 18, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 9, 9, 728)    186368      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 9, 9, 728)    2912        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 9, 9, 728)    0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 5, 5, 1024)   745472      add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 5, 5, 1024)   4096        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 5,496,320\n",
            "Non-trainable params: 15,365,160\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGDGaTyDObch",
        "colab_type": "text"
      },
      "source": [
        "Sources found here at (1-2 for each section): \n",
        "\n",
        "1. https://pathmind.com/wiki/ai-vs-machine-learning-vs-deep-learning\n",
        "\n",
        "2. https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\n",
        "\n",
        "3. https://cs231n.github.io/convolutional-networks/\n",
        "\n",
        "4. https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/\n",
        "\n",
        "5. https://machinelearningmastery.com/learning-rate-for-deep-learning-neural-networks/\n",
        "\n",
        "6. https://medium.com/swlh/overfitting-vs-underfitting-d742b4ffac57\n",
        "\n",
        "7. https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/\n",
        "\n",
        "8. https://flyyufelix.github.io/2016/10/03/fine-tuning-in-keras-part1.html"
      ]
    }
  ]
}